"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[8279],{1539:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-digital-twin/week-5-high-fidelity-rendering-in-unity","title":"High-Fidelity Rendering in Unity","description":"Learning Objectives","source":"@site/docs/module-2-digital-twin/week-5-high-fidelity-rendering-in-unity.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/week-5-high-fidelity-rendering-in-unity","permalink":"/hackathon_textbook_ai_robotics/docs/module-2-digital-twin/week-5-high-fidelity-rendering-in-unity","draft":false,"unlisted":false,"editUrl":"https://github.com/muhammadwaheedairi/hackathon_textbook_ai_robotics/edit/main/my-website/docs/module-2-digital-twin/week-5-high-fidelity-rendering-in-unity.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"High-Fidelity Rendering in Unity","sidebar_label":"Week 5: High-Fidelity Rendering in Unity","sidebar_position":2},"sidebar":"textbookSidebar","previous":{"title":"Week 4: Physics Simulation in Gazebo","permalink":"/hackathon_textbook_ai_robotics/docs/module-2-digital-twin/week-4-physics-simulation-in-gazebo"},"next":{"title":"Week 6 - NVIDIA Isaac Sim","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/week-6-nvidia-isaac-sim"}}');var a=i(4848),r=i(8453);const o={title:"High-Fidelity Rendering in Unity",sidebar_label:"Week 5: High-Fidelity Rendering in Unity",sidebar_position:2},l="High-Fidelity Rendering in Unity",s={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Theory",id:"theory",level:2},{value:"Unity Rendering Pipelines",id:"unity-rendering-pipelines",level:3},{value:"Built-in Render Pipeline",id:"built-in-render-pipeline",level:4},{value:"Universal Render Pipeline (URP)",id:"universal-render-pipeline-urp",level:4},{value:"High Definition Render Pipeline (HDRP)",id:"high-definition-render-pipeline-hdrp",level:4},{value:"Physically-Based Rendering (PBR)",id:"physically-based-rendering-pbr",level:3},{value:"Albedo (Base Color)",id:"albedo-base-color",level:4},{value:"Metallic",id:"metallic",level:4},{value:"Smoothness/Roughness",id:"smoothnessroughness",level:4},{value:"Normal Maps",id:"normal-maps",level:4},{value:"Occlusion Maps",id:"occlusion-maps",level:4},{value:"Lighting Systems in Unity",id:"lighting-systems-in-unity",level:3},{value:"Real-time Lighting",id:"real-time-lighting",level:4},{value:"Baked Lighting",id:"baked-lighting",level:4},{value:"Mixed Lighting",id:"mixed-lighting",level:4},{value:"Unity Sensor Simulation",id:"unity-sensor-simulation",level:3},{value:"Camera Simulation",id:"camera-simulation",level:4},{value:"LIDAR Simulation",id:"lidar-simulation",level:4},{value:"IMU Simulation",id:"imu-simulation",level:4},{value:"Unity Robotics Integration",id:"unity-robotics-integration",level:3},{value:"Unity Robotics Hub",id:"unity-robotics-hub",level:4},{value:"Unity Simulation Framework",id:"unity-simulation-framework",level:4},{value:"Asset Packages for Robotics",id:"asset-packages-for-robotics",level:4},{value:"Performance Optimization for Real-Time Rendering",id:"performance-optimization-for-real-time-rendering",level:3},{value:"Level of Detail (LOD)",id:"level-of-detail-lod",level:4},{value:"Occlusion Culling",id:"occlusion-culling",level:4},{value:"Dynamic Batching",id:"dynamic-batching",level:4},{value:"Shader Optimization",id:"shader-optimization",level:4},{value:"Code Examples",id:"code-examples",level:2},{value:"Unity C# Script for Camera Sensor Simulation",id:"unity-c-script-for-camera-sensor-simulation",level:3},{value:"Unity C# Script for LIDAR Simulation",id:"unity-c-script-for-lidar-simulation",level:3},{value:"Unity C# Script for IMU Simulation",id:"unity-c-script-for-imu-simulation",level:3},{value:"Unity C# Script for Physics-Based Environment Generation",id:"unity-c-script-for-physics-based-environment-generation",level:3},{value:"Exercises",id:"exercises",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"high-fidelity-rendering-in-unity",children:"High-Fidelity Rendering in Unity"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this week, students will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understand the fundamentals of high-fidelity rendering in Unity"}),"\n",(0,a.jsx)(n.li,{children:"Configure Unity for photorealistic visualization"}),"\n",(0,a.jsx)(n.li,{children:"Implement advanced lighting and material systems"}),"\n",(0,a.jsx)(n.li,{children:"Integrate Unity with robotics simulation frameworks"}),"\n",(0,a.jsx)(n.li,{children:"Create realistic sensor simulation in Unity environments"}),"\n",(0,a.jsx)(n.li,{children:"Optimize rendering performance for real-time applications"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(n.p,{children:"High-fidelity rendering in Unity has become increasingly important for robotics applications, particularly for creating realistic training environments for AI systems and simulating sensor data with photorealistic quality. Unity's advanced rendering pipeline, including the High Definition Render Pipeline (HDRP) and Universal Render Pipeline (URP), enables the creation of photorealistic environments that can be used for synthetic data generation, sensor simulation, and human-in-the-loop testing. This week explores the fundamentals of high-fidelity rendering in Unity and its applications in robotics simulation."}),"\n",(0,a.jsx)(n.p,{children:"Unity's rendering capabilities have evolved significantly, offering features like real-time ray tracing, physically-based rendering (PBR), global illumination, and advanced post-processing effects. These features make Unity an excellent platform for creating realistic digital twins of physical environments, which are essential for training robust perception systems in robotics. The integration of Unity with robotics frameworks enables seamless transfer of simulated data to real-world applications."}),"\n",(0,a.jsx)(n.h2,{id:"theory",children:"Theory"}),"\n",(0,a.jsx)(n.h3,{id:"unity-rendering-pipelines",children:"Unity Rendering Pipelines"}),"\n",(0,a.jsx)(n.p,{children:"Unity offers three main rendering pipelines optimized for different use cases:"}),"\n",(0,a.jsx)(n.h4,{id:"built-in-render-pipeline",children:"Built-in Render Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"The legacy rendering pipeline that offers basic rendering capabilities and is suitable for simple applications. While still functional, it lacks many of the advanced features available in the newer pipelines."}),"\n",(0,a.jsx)(n.h4,{id:"universal-render-pipeline-urp",children:"Universal Render Pipeline (URP)"}),"\n",(0,a.jsx)(n.p,{children:"A lightweight, flexible rendering pipeline designed for performance across a wide range of platforms. URP provides a good balance between visual quality and performance, making it suitable for mobile robotics applications and applications requiring high frame rates."}),"\n",(0,a.jsx)(n.p,{children:"Key features of URP:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Lightweight and efficient"}),"\n",(0,a.jsx)(n.li,{children:"Supports 2D and 3D rendering"}),"\n",(0,a.jsx)(n.li,{children:"Customizable render passes"}),"\n",(0,a.jsx)(n.li,{children:"Built-in post-processing effects"}),"\n",(0,a.jsx)(n.li,{children:"Shader Graph integration"}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"high-definition-render-pipeline-hdrp",children:"High Definition Render Pipeline (HDRP)"}),"\n",(0,a.jsx)(n.p,{children:"A state-of-the-art rendering pipeline designed for high-fidelity visuals on powerful hardware. HDRP is ideal for applications requiring photorealistic rendering, such as digital twin creation and high-quality sensor simulation."}),"\n",(0,a.jsx)(n.p,{children:"Key features of HDRP:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Physically-based rendering"}),"\n",(0,a.jsx)(n.li,{children:"Real-time ray tracing"}),"\n",(0,a.jsx)(n.li,{children:"Advanced lighting models"}),"\n",(0,a.jsx)(n.li,{children:"Global illumination (Baked and realtime)"}),"\n",(0,a.jsx)(n.li,{children:"Volumetric effects"}),"\n",(0,a.jsx)(n.li,{children:"Advanced post-processing stack"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"physically-based-rendering-pbr",children:"Physically-Based Rendering (PBR)"}),"\n",(0,a.jsx)(n.p,{children:"Physically-Based Rendering is a methodology that simulates light-object interactions using real-world physics principles. PBR materials in Unity are defined by several key properties:"}),"\n",(0,a.jsx)(n.h4,{id:"albedo-base-color",children:"Albedo (Base Color)"}),"\n",(0,a.jsx)(n.p,{children:"The base color of the material without lighting considerations. This represents the color of the surface when illuminated by white light."}),"\n",(0,a.jsx)(n.h4,{id:"metallic",children:"Metallic"}),"\n",(0,a.jsx)(n.p,{children:"Controls whether a surface behaves like a metal or a non-metal. Metallic surfaces reflect light as colored reflections, while non-metallic surfaces reflect light as white highlights."}),"\n",(0,a.jsx)(n.h4,{id:"smoothnessroughness",children:"Smoothness/Roughness"}),"\n",(0,a.jsx)(n.p,{children:"Controls the microsurface detail of the material, affecting how light scatters. Smooth surfaces create sharp reflections, while rough surfaces create diffuse reflections."}),"\n",(0,a.jsx)(n.h4,{id:"normal-maps",children:"Normal Maps"}),"\n",(0,a.jsx)(n.p,{children:"Provide detailed surface geometry information without increasing polygon count. Normal maps create the illusion of complex surface details like scratches, bumps, and grooves."}),"\n",(0,a.jsx)(n.h4,{id:"occlusion-maps",children:"Occlusion Maps"}),"\n",(0,a.jsx)(n.p,{children:"Simulate the shadowing effect of small surface details, enhancing the perception of depth and contact between surfaces."}),"\n",(0,a.jsx)(n.h3,{id:"lighting-systems-in-unity",children:"Lighting Systems in Unity"}),"\n",(0,a.jsx)(n.p,{children:"Unity provides several lighting systems that can be used to create realistic illumination:"}),"\n",(0,a.jsx)(n.h4,{id:"real-time-lighting",children:"Real-time Lighting"}),"\n",(0,a.jsx)(n.p,{children:"Lights that affect objects dynamically during gameplay. Real-time lighting provides interactive illumination but can be computationally expensive."}),"\n",(0,a.jsx)(n.p,{children:"Types of real-time lights:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Directional lights: Simulate distant light sources like the sun"}),"\n",(0,a.jsx)(n.li,{children:"Point lights: Emit light in all directions from a point"}),"\n",(0,a.jsx)(n.li,{children:"Spot lights: Emit light in a cone shape"}),"\n",(0,a.jsx)(n.li,{children:"Area lights: Emit light from a surface area (baked only in some pipelines)"}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"baked-lighting",children:"Baked Lighting"}),"\n",(0,a.jsx)(n.p,{children:"Lighting that is precomputed and stored in lightmaps. Baked lighting provides high-quality global illumination but cannot change at runtime."}),"\n",(0,a.jsx)(n.h4,{id:"mixed-lighting",children:"Mixed Lighting"}),"\n",(0,a.jsx)(n.p,{children:"Combines real-time and baked lighting, allowing for static lighting to be baked while enabling dynamic shadows from moving objects."}),"\n",(0,a.jsx)(n.h3,{id:"unity-sensor-simulation",children:"Unity Sensor Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Unity can simulate various sensor types used in robotics, providing realistic sensor data for testing and training:"}),"\n",(0,a.jsx)(n.h4,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Unity's camera components can simulate various camera types:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"RGB cameras for visual perception"}),"\n",(0,a.jsx)(n.li,{children:"Depth cameras for 3D reconstruction"}),"\n",(0,a.jsx)(n.li,{children:"Semantic segmentation cameras for object recognition"}),"\n",(0,a.jsx)(n.li,{children:"Stereo cameras for depth perception"}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,a.jsx)(n.p,{children:"LIDAR sensors can be simulated using raycasting techniques, providing accurate distance measurements and point cloud data similar to real LIDAR sensors."}),"\n",(0,a.jsx)(n.h4,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Inertial measurement units can be simulated by tracking the acceleration and rotation of objects in the Unity scene, providing realistic IMU data for navigation algorithms."}),"\n",(0,a.jsx)(n.h3,{id:"unity-robotics-integration",children:"Unity Robotics Integration"}),"\n",(0,a.jsx)(n.p,{children:"Unity provides several tools and packages for robotics integration:"}),"\n",(0,a.jsx)(n.h4,{id:"unity-robotics-hub",children:"Unity Robotics Hub"}),"\n",(0,a.jsx)(n.p,{children:"A collection of tools and packages that facilitate robotics development in Unity, including:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"ROS# for ROS communication"}),"\n",(0,a.jsx)(n.li,{children:"ML-Agents for reinforcement learning"}),"\n",(0,a.jsx)(n.li,{children:"Unity Perception for synthetic data generation"}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"unity-simulation-framework",children:"Unity Simulation Framework"}),"\n",(0,a.jsx)(n.p,{children:"The framework enables the creation of complex simulation environments with realistic physics and rendering, allowing for comprehensive testing of robotics algorithms."}),"\n",(0,a.jsx)(n.h4,{id:"asset-packages-for-robotics",children:"Asset Packages for Robotics"}),"\n",(0,a.jsx)(n.p,{children:"Unity provides specialized asset packages for robotics simulation, including:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Procedural environment generation"}),"\n",(0,a.jsx)(n.li,{children:"Physics-based robot models"}),"\n",(0,a.jsx)(n.li,{children:"Sensor simulation tools"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"performance-optimization-for-real-time-rendering",children:"Performance Optimization for Real-Time Rendering"}),"\n",(0,a.jsx)(n.p,{children:"High-fidelity rendering can be computationally intensive. Several optimization strategies help maintain performance:"}),"\n",(0,a.jsx)(n.h4,{id:"level-of-detail-lod",children:"Level of Detail (LOD)"}),"\n",(0,a.jsx)(n.p,{children:"Implementing multiple levels of detail for 3D models allows the renderer to use simpler representations when objects are far from the camera."}),"\n",(0,a.jsx)(n.h4,{id:"occlusion-culling",children:"Occlusion Culling"}),"\n",(0,a.jsx)(n.p,{children:"Hiding objects that are not visible to the camera based on occlusion data reduces unnecessary rendering calculations."}),"\n",(0,a.jsx)(n.h4,{id:"dynamic-batching",children:"Dynamic Batching"}),"\n",(0,a.jsx)(n.p,{children:"Combining multiple small objects with the same materials into single draw calls reduces the number of rendering operations."}),"\n",(0,a.jsx)(n.h4,{id:"shader-optimization",children:"Shader Optimization"}),"\n",(0,a.jsx)(n.p,{children:"Using efficient shaders and minimizing overdraw helps maintain high frame rates in complex scenes."}),"\n",(0,a.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,a.jsx)(n.h3,{id:"unity-c-script-for-camera-sensor-simulation",children:"Unity C# Script for Camera Sensor Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of how to implement camera sensor simulation in Unity:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:'using System;\nusing UnityEngine;\nusing System.Collections;\nusing System.IO;\n\n[RequireComponent(typeof(Camera))]\npublic class CameraSensor : MonoBehaviour\n{\n    [Header("Camera Settings")]\n    public int imageWidth = 640;\n    public int imageHeight = 480;\n    public float fieldOfView = 60f;\n    public string outputDirectory = "CameraOutput";\n\n    [Header("Sensor Simulation")]\n    public bool simulateDepth = false;\n    public float minDepth = 0.1f;\n    public float maxDepth = 100f;\n    public bool simulateSemanticSegmentation = false;\n\n    private Camera cam;\n    private RenderTexture renderTexture;\n    private Texture2D outputTexture;\n\n    void Start()\n    {\n        cam = GetComponent<Camera>();\n        SetupCamera();\n        CreateRenderTexture();\n    }\n\n    void SetupCamera()\n    {\n        cam.fieldOfView = fieldOfView;\n        cam.enabled = false; // Disable default rendering\n    }\n\n    void CreateRenderTexture()\n    {\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\n        renderTexture.format = RenderTextureFormat.ARGB32;\n        renderTexture.antiAliasing = 1;\n        renderTexture.Create();\n\n        outputTexture = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);\n    }\n\n    public void CaptureImage()\n    {\n        // Set the camera\'s target texture\n        cam.targetTexture = renderTexture;\n\n        // Render the camera\n        cam.Render();\n\n        // Read the render texture into the output texture\n        RenderTexture.active = renderTexture;\n        outputTexture.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\n        outputTexture.Apply();\n\n        // Reset render texture\n        RenderTexture.active = null;\n        cam.targetTexture = null;\n\n        // Save the image\n        SaveImage(outputTexture, "rgb_image");\n    }\n\n    public void CaptureDepthImage()\n    {\n        if (!simulateDepth) return;\n\n        // Create a temporary render texture for depth\n        RenderTexture depthRT = RenderTexture.GetTemporary(\n            imageWidth, imageHeight, 24, RenderTextureFormat.RFloat);\n\n        // Set up camera for depth rendering\n        cam.SetTargetBuffers(depthRT.colorBuffer, depthRT.depthBuffer);\n        cam.RenderWithShader(Shader.Find("Hidden/DepthOnly"), "");\n\n        // Read depth data\n        RenderTexture.active = depthRT;\n        Texture2D depthTexture = new Texture2D(imageWidth, imageHeight, TextureFormat.RFloat, false);\n        depthTexture.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\n        depthTexture.Apply();\n\n        // Reset\n        RenderTexture.active = null;\n        cam.ResetReplacementShader();\n\n        // Save the depth image\n        SaveImage(depthTexture, "depth_image");\n\n        // Clean up\n        RenderTexture.ReleaseTemporary(depthRT);\n        DestroyImmediate(depthTexture);\n    }\n\n    private void SaveImage(Texture2D texture, string prefix)\n    {\n        byte[] bytes = texture.EncodeToPNG();\n\n        // Create directory if it doesn\'t exist\n        string fullDir = Path.Combine(Application.dataPath, outputDirectory);\n        if (!Directory.Exists(fullDir))\n        {\n            Directory.CreateDirectory(fullDir);\n        }\n\n        // Generate filename with timestamp\n        string filename = $"{prefix}_{DateTime.Now:yyyyMMdd_HHmmss}.png";\n        string filepath = Path.Combine(fullDir, filename);\n\n        File.WriteAllBytes(filepath, bytes);\n        Debug.Log($"Image saved to: {filepath}");\n    }\n\n    void OnDestroy()\n    {\n        if (renderTexture != null)\n        {\n            renderTexture.Release();\n        }\n        if (outputTexture != null)\n        {\n            DestroyImmediate(outputTexture);\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"unity-c-script-for-lidar-simulation",children:"Unity C# Script for LIDAR Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of how to simulate LIDAR sensors in Unity:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:'using System.Collections.Generic;\nusing UnityEngine;\n\npublic class LIDARSensor : MonoBehaviour\n{\n    [Header("LIDAR Configuration")]\n    public int numberOfRays = 360;\n    public float minAngle = -90f;\n    public float maxAngle = 90f;\n    public float maxDistance = 20f;\n    public LayerMask detectionMask = -1;\n    public string outputTopic = "/laser_scan";\n\n    [Header("Performance")]\n    public float updateRate = 10f; // Hz\n    public bool visualizeRays = true;\n\n    private LineRenderer lineRenderer;\n    private float updateInterval;\n    private float lastUpdateTime;\n\n    // Data structure for LIDAR output\n    [System.Serializable]\n    public class LaserScanData\n    {\n        public float[] ranges;\n        public float angle_min;\n        public float angle_max;\n        public float angle_increment;\n        public float time_increment;\n        public float scan_time;\n        public float range_min;\n        public float range_max;\n    }\n\n    void Start()\n    {\n        updateInterval = 1f / updateRate;\n        lastUpdateTime = 0f;\n\n        if (visualizeRays)\n        {\n            SetupLineRenderer();\n        }\n    }\n\n    void SetupLineRenderer()\n    {\n        lineRenderer = gameObject.AddComponent<LineRenderer>();\n        lineRenderer.material = new Material(Shader.Find("Sprites/Default"));\n        lineRenderer.widthMultiplier = 0.02f;\n        lineRenderer.positionCount = numberOfRays + 1;\n        lineRenderer.useWorldSpace = false;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= updateInterval)\n        {\n            PerformLIDARScan();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    public LaserScanData PerformLIDARScan()\n    {\n        LaserScanData scanData = new LaserScanData();\n        scanData.ranges = new float[numberOfRays];\n        scanData.angle_min = minAngle * Mathf.Deg2Rad;\n        scanData.angle_max = maxAngle * Mathf.Deg2Rad;\n        scanData.angle_increment = (maxAngle - minAngle) * Mathf.Deg2Rad / numberOfRays;\n        scanData.time_increment = 0f;\n        scanData.scan_time = updateInterval;\n        scanData.range_min = 0.1f;\n        scanData.range_max = maxDistance;\n\n        float angleStep = (maxAngle - minAngle) / numberOfRays;\n\n        for (int i = 0; i < numberOfRays; i++)\n        {\n            float angle = minAngle + i * angleStep;\n            float radians = angle * Mathf.Deg2Rad;\n\n            // Calculate ray direction in local space\n            Vector3 rayDirection = new Vector3(\n                Mathf.Cos(radians),\n                0f,\n                Mathf.Sin(radians)\n            );\n\n            // Transform to world space\n            Vector3 worldRayDirection = transform.TransformDirection(rayDirection);\n\n            // Perform raycast\n            RaycastHit hit;\n            if (Physics.Raycast(transform.position, worldRayDirection, out hit, maxDistance, detectionMask))\n            {\n                scanData.ranges[i] = hit.distance;\n\n                // Visualize ray if enabled\n                if (visualizeRays && lineRenderer != null)\n                {\n                    lineRenderer.SetPosition(i, Vector3.zero);\n                    lineRenderer.SetPosition(i + 1, transform.InverseTransformPoint(hit.point));\n                }\n            }\n            else\n            {\n                scanData.ranges[i] = float.PositiveInfinity;\n\n                // Visualize ray to max distance if enabled\n                if (visualizeRays && lineRenderer != null)\n                {\n                    Vector3 maxPoint = transform.InverseTransformPoint(\n                        transform.position + worldRayDirection * maxDistance\n                    );\n                    lineRenderer.SetPosition(i, Vector3.zero);\n                    lineRenderer.SetPosition(i + 1, maxPoint);\n                }\n            }\n        }\n\n        return scanData;\n    }\n\n    // Method to get point cloud from LIDAR data\n    public List<Vector3> GetPointCloud(LaserScanData scanData)\n    {\n        List<Vector3> pointCloud = new List<Vector3>();\n        Vector3 sensorPosition = transform.position;\n\n        for (int i = 0; i < scanData.ranges.Length; i++)\n        {\n            float range = scanData.ranges[i];\n            if (range > scanData.range_min && range < scanData.range_max)\n            {\n                float angle = scanData.angle_min + i * scanData.angle_increment;\n\n                // Calculate point in 2D plane (for 2D LIDAR)\n                Vector3 point = new Vector3(\n                    range * Mathf.Cos(angle),\n                    0f,\n                    range * Mathf.Sin(angle)\n                );\n\n                // Transform to world coordinates\n                point = transform.TransformPoint(point);\n                pointCloud.Add(point);\n            }\n        }\n\n        return pointCloud;\n    }\n\n    // Method to simulate 3D LIDAR by stacking 2D scans\n    public List<Vector3> Get3DPointCloud(int verticalBeams = 16, float verticalFOV = 30f)\n    {\n        List<Vector3> pointCloud = new List<Vector3>();\n\n        for (int v = 0; v < verticalBeams; v++)\n        {\n            float verticalAngle = -verticalFOV / 2 + (v * verticalFOV / (verticalBeams - 1));\n\n            // Rotate the sensor temporarily for vertical angle\n            Vector3 originalEuler = transform.eulerAngles;\n            transform.eulerAngles = new Vector3(\n                originalEuler.x + verticalAngle,\n                originalEuler.y,\n                originalEuler.z\n            );\n\n            // Perform scan at this vertical angle\n            LaserScanData scanData = PerformLIDARScan();\n            List<Vector3> scanPoints = GetPointCloud(scanData);\n            pointCloud.AddRange(scanPoints);\n\n            // Restore original rotation\n            transform.eulerAngles = originalEuler;\n        }\n\n        return pointCloud;\n    }\n\n    void OnValidate()\n    {\n        numberOfRays = Mathf.Clamp(numberOfRays, 1, 10000);\n        maxDistance = Mathf.Clamp(maxDistance, 0.1f, 1000f);\n        updateRate = Mathf.Clamp(updateRate, 0.1f, 100f);\n    }\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"unity-c-script-for-imu-simulation",children:"Unity C# Script for IMU Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of how to simulate IMU sensors in Unity:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:'using System.Collections;\nusing UnityEngine;\n\npublic class IMUSensor : MonoBehaviour\n{\n    [Header("IMU Configuration")]\n    public float updateRate = 100f; // Hz\n    public bool includeGyroscope = true;\n    public bool includeAccelerometer = true;\n    public bool includeMagnetometer = false;\n\n    [Header("Noise Parameters")]\n    public float accelerometerNoise = 0.01f;\n    public float gyroscopeNoise = 0.01f;\n    public float magnetometerNoise = 0.1f;\n\n    [Header("Gravity")]\n    public Vector3 gravity = new Vector3(0, -9.81f, 0);\n\n    private float updateInterval;\n    private float lastUpdateTime;\n\n    // Data structure for IMU output\n    [System.Serializable]\n    public class IMUData\n    {\n        public Vector3 linear_acceleration;\n        public Vector3 angular_velocity;\n        public Vector3 magnetic_field;\n        public Quaternion orientation;\n    }\n\n    // Store previous state for velocity calculation\n    private Vector3 previousPosition;\n    private Quaternion previousRotation;\n    private float previousTime;\n\n    void Start()\n    {\n        updateInterval = 1f / updateRate;\n        lastUpdateTime = Time.time;\n\n        previousPosition = transform.position;\n        previousRotation = transform.rotation;\n        previousTime = Time.time;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= updateInterval)\n        {\n            PublishIMUData();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    public IMUData GetIMUData()\n    {\n        IMUData imuData = new IMUData();\n\n        // Calculate linear acceleration\n        if (includeAccelerometer)\n        {\n            Vector3 currentPosition = transform.position;\n            float currentTime = Time.time;\n\n            // Calculate velocity from position changes\n            Vector3 velocity = (currentPosition - previousPosition) / (currentTime - previousTime);\n            Vector3 previousVelocity = (previousPosition - GetPreviousPosition(2)) / (currentTime - previousTime);\n\n            // Calculate acceleration from velocity changes\n            Vector3 acceleration = (velocity - previousVelocity) / (currentTime - previousTime);\n\n            // Add gravity compensation (remove gravity from linear acceleration)\n            imuData.linear_acceleration = acceleration - transform.InverseTransformDirection(gravity);\n\n            // Add noise\n            imuData.linear_acceleration += AddNoiseVector(accelerometerNoise);\n        }\n\n        // Calculate angular velocity\n        if (includeGyroscope)\n        {\n            Quaternion currentRotation = transform.rotation;\n            float currentTime = Time.time;\n\n            // Calculate angular velocity from rotation changes\n            Quaternion deltaRotation = currentRotation * Quaternion.Inverse(previousRotation);\n            Vector3 angularVelocity = new Vector3();\n\n            float deltaTime = currentTime - previousTime;\n            if (deltaTime > 0)\n            {\n                // Convert quaternion to angular velocity\n                float angle;\n                Vector3 axis;\n                deltaRotation.ToAngleAxis(out angle, out axis);\n\n                // Convert from degrees to radians and normalize by time\n                angularVelocity = axis * Mathf.Deg2Rad * angle / deltaTime;\n            }\n\n            imuData.angular_velocity = transform.InverseTransformDirection(angularVelocity);\n\n            // Add noise\n            imuData.angular_velocity += AddNoiseVector(gyroscopeNoise);\n        }\n\n        // Simulate magnetic field\n        if (includeMagnetometer)\n        {\n            // In a real implementation, this would be based on geographic location\n            // For simulation, we\'ll use a fixed magnetic field vector\n            imuData.magnetic_field = transform.InverseTransformDirection(new Vector3(22.9f, 0f, 44.4f)); // Approximate magnetic field in microteslas\n\n            // Add noise\n            imuData.magnetic_field += AddNoiseVector(magnetometerNoise);\n        }\n\n        // Calculate orientation\n        imuData.orientation = transform.rotation;\n\n        // Update previous state\n        previousPosition = transform.position;\n        previousRotation = transform.rotation;\n        previousTime = Time.time;\n\n        return imuData;\n    }\n\n    private Vector3 GetPreviousPosition(int framesAgo)\n    {\n        // In a real implementation, you\'d store multiple previous positions\n        // For simplicity, we\'ll just return the last known position\n        return previousPosition;\n    }\n\n    private Vector3 AddNoiseVector(float noiseLevel)\n    {\n        return new Vector3(\n            Random.Range(-noiseLevel, noiseLevel),\n            Random.Range(-noiseLevel, noiseLevel),\n            Random.Range(-noiseLevel, noiseLevel)\n        );\n    }\n\n    public void PublishIMUData()\n    {\n        IMUData data = GetIMUData();\n\n        // In a real implementation, this would publish to ROS or another messaging system\n        Debug.Log($"IMU Data - Accel: {data.linear_acceleration}, Gyro: {data.angular_velocity}");\n    }\n\n    // Method to get acceleration in world frame\n    public Vector3 GetWorldAcceleration()\n    {\n        IMUData data = GetIMUData();\n        return transform.TransformDirection(data.linear_acceleration);\n    }\n\n    // Method to get angular velocity in world frame\n    public Vector3 GetWorldAngularVelocity()\n    {\n        IMUData data = GetIMUData();\n        return transform.TransformDirection(data.angular_velocity);\n    }\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"unity-c-script-for-physics-based-environment-generation",children:"Unity C# Script for Physics-Based Environment Generation"}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of how to procedurally generate physics-based environments in Unity:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:'using System.Collections.Generic;\nusing UnityEngine;\n\npublic class PhysicsEnvironmentGenerator : MonoBehaviour\n{\n    [Header("Terrain Generation")]\n    public int terrainWidth = 200;\n    public int terrainLength = 200;\n    public float terrainHeight = 20f;\n    public int resolution = 256;\n\n    [Header("Object Placement")]\n    public GameObject[] obstaclePrefabs;\n    public int minObstacles = 10;\n    public int maxObstacles = 50;\n    public float placementAreaPadding = 5f;\n\n    [Header("Material Properties")]\n    public PhysicMaterial defaultMaterial;\n    public float dynamicFriction = 0.6f;\n    public float staticFriction = 0.6f;\n    public float bounciness = 0.1f;\n\n    [Header("Environment Features")]\n    public bool generateRandomTerrain = true;\n    public bool addStaticObstacles = true;\n    public bool addDynamicObstacles = true;\n    public bool addRamps = false;\n    public int numRamps = 3;\n\n    private List<GameObject> spawnedObjects = new List<GameObject>();\n    private float[,] heightMap;\n\n    void Start()\n    {\n        GenerateEnvironment();\n    }\n\n    public void GenerateEnvironment()\n    {\n        ClearEnvironment();\n\n        if (generateRandomTerrain)\n        {\n            GenerateTerrain();\n        }\n\n        if (addStaticObstacles)\n        {\n            PlaceStaticObstacles();\n        }\n\n        if (addDynamicObstacles)\n        {\n            PlaceDynamicObstacles();\n        }\n\n        if (addRamps)\n        {\n            PlaceRamps();\n        }\n    }\n\n    void ClearEnvironment()\n    {\n        // Destroy previously spawned objects\n        foreach (GameObject obj in spawnedObjects)\n        {\n            if (obj != null)\n            {\n                DestroyImmediate(obj);\n            }\n        }\n        spawnedObjects.Clear();\n    }\n\n    void GenerateTerrain()\n    {\n        // Create terrain programmatically\n        GameObject terrainObj = new GameObject("GeneratedTerrain");\n        Terrain terrain = terrainObj.AddComponent<Terrain>();\n        TerrainCollider terrainCollider = terrainObj.AddComponent<TerrainCollider>();\n\n        // Create terrain data\n        TerrainData terrainData = new TerrainData();\n        terrainData.heightmapResolution = resolution;\n        terrainData.size = new Vector3(terrainWidth, terrainHeight, terrainLength);\n\n        // Generate heightmap\n        heightMap = GenerateHeightMap(resolution, resolution);\n        terrainData.SetHeights(0, 0, heightMap);\n\n        // Assign the terrain data\n        terrain.terrainData = terrainData;\n        terrainCollider.terrainData = terrainData;\n\n        spawnedObjects.Add(terrainObj);\n    }\n\n    float[,] GenerateHeightMap(int width, int height)\n    {\n        float[,] heights = new float[width, height];\n\n        for (int x = 0; x < width; x++)\n        {\n            for (int y = 0; y < height; y++)\n            {\n                // Generate Perlin noise-based terrain\n                float xCoord = (float)x / width * 10f;\n                float yCoord = (float)y / height * 10f;\n\n                // Multiple octaves for more natural terrain\n                float elevation = 0f;\n                float amplitude = 1f;\n                float frequency = 1f;\n                float persistence = 0.5f;\n\n                for (int octave = 0; octave < 4; octave++)\n                {\n                    elevation += Mathf.PerlinNoise(xCoord * frequency, yCoord * frequency) * amplitude;\n                    amplitude *= persistence;\n                    frequency *= 2f;\n                }\n\n                // Normalize to 0-1 range and apply to height\n                heights[x, y] = elevation / 4f; // Divide by number of octaves for normalization\n            }\n        }\n\n        return heights;\n    }\n\n    void PlaceStaticObstacles()\n    {\n        int numObstacles = Random.Range(minObstacles, maxObstacles + 1);\n\n        for (int i = 0; i < numObstacles; i++)\n        {\n            if (obstaclePrefabs.Length == 0) continue;\n\n            // Select random obstacle prefab\n            GameObject obstaclePrefab = obstaclePrefabs[Random.Range(0, obstaclePrefabs.Length)];\n\n            // Generate random position within bounds\n            Vector3 position = new Vector3(\n                Random.Range(placementAreaPadding, terrainWidth - placementAreaPadding),\n                10f, // Start above ground to let it fall\n                Random.Range(placementAreaPadding, terrainLength - placementAreaPadding)\n            );\n\n            // Create obstacle\n            GameObject obstacle = Instantiate(obstaclePrefab, position, Quaternion.identity);\n\n            // Add rigidbody if it doesn\'t have one\n            if (obstacle.GetComponent<Rigidbody>() == null)\n            {\n                Rigidbody rb = obstacle.AddComponent<Rigidbody>();\n                rb.isKinematic = true; // Static obstacles\n            }\n\n            // Set material properties\n            SetPhysicsMaterial(obstacle);\n\n            spawnedObjects.Add(obstacle);\n        }\n    }\n\n    void PlaceDynamicObstacles()\n    {\n        int numObstacles = Random.Range(minObstacles / 2, maxObstacles / 2 + 1);\n\n        for (int i = 0; i < numObstacles; i++)\n        {\n            if (obstaclePrefabs.Length == 0) continue;\n\n            // Select random obstacle prefab\n            GameObject obstaclePrefab = obstaclePrefabs[Random.Range(0, obstaclePrefabs.Length)];\n\n            // Generate random position within bounds\n            Vector3 position = new Vector3(\n                Random.Range(placementAreaPadding, terrainWidth - placementAreaPadding),\n                10f, // Start above ground\n                Random.Range(placementAreaPadding, terrainLength - placementAreaPadding)\n            );\n\n            // Create obstacle\n            GameObject obstacle = Instantiate(obstaclePrefab, position, Quaternion.identity);\n\n            // Add rigidbody for physics simulation\n            Rigidbody rb = obstacle.GetComponent<Rigidbody>();\n            if (rb == null)\n            {\n                rb = obstacle.AddComponent<Rigidbody>();\n            }\n\n            // Set as dynamic\n            rb.isKinematic = false;\n            rb.useGravity = true;\n\n            // Add random initial velocity\n            rb.velocity = new Vector3(\n                Random.Range(-1f, 1f),\n                0f,\n                Random.Range(-1f, 1f)\n            ) * 2f;\n\n            // Set material properties\n            SetPhysicsMaterial(obstacle);\n\n            spawnedObjects.Add(obstacle);\n        }\n    }\n\n    void PlaceRamps()\n    {\n        for (int i = 0; i < numRamps; i++)\n        {\n            // Create a ramp object\n            GameObject ramp = GameObject.CreatePrimitive(PrimitiveType.Capsule);\n            ramp.name = "Ramp_" + i;\n\n            // Position the ramp\n            Vector3 position = new Vector3(\n                Random.Range(placementAreaPadding + 10, terrainWidth - placementAreaPadding - 10),\n                5f,\n                Random.Range(placementAreaPadding + 10, terrainLength - placementAreaPadding - 10)\n            );\n\n            ramp.transform.position = position;\n\n            // Rotate to create an incline\n            float angle = Random.Range(15f, 45f);\n            ramp.transform.rotation = Quaternion.Euler(angle, Random.Range(0f, 360f), 0f);\n\n            // Scale to make it ramp-like\n            ramp.transform.localScale = new Vector3(0.5f, 5f, 3f);\n\n            // Add rigidbody\n            Rigidbody rb = ramp.AddComponent<Rigidbody>();\n            rb.isKinematic = true; // Static ramp\n\n            // Set material properties\n            SetPhysicsMaterial(ramp);\n\n            // Remove the collider and add a box collider instead for better physics\n            DestroyImmediate(ramp.GetComponent<CapsuleCollider>());\n            BoxCollider boxCollider = ramp.AddComponent<BoxCollider>();\n            boxCollider.size = new Vector3(1f, 10f, 6f);\n\n            spawnedObjects.Add(ramp);\n        }\n    }\n\n    void SetPhysicsMaterial(GameObject obj)\n    {\n        PhysicMaterial material = defaultMaterial;\n        if (material == null)\n        {\n            material = new PhysicMaterial("GeneratedMaterial");\n            material.dynamicFriction = dynamicFriction;\n            material.staticFriction = staticFriction;\n            material.bounciness = bounciness;\n        }\n\n        // Apply material to all colliders in the object\n        Collider[] colliders = obj.GetComponentsInChildren<Collider>();\n        foreach (Collider collider in colliders)\n        {\n            collider.material = material;\n        }\n    }\n\n    // Method to modify terrain height at a specific point (for dynamic terrain modification)\n    public void ModifyTerrainHeight(Vector3 worldPosition, float heightDelta, float radius)\n    {\n        if (heightMap == null) return;\n\n        Terrain terrain = GetComponent<Terrain>();\n        if (terrain == null) return;\n\n        TerrainData terrainData = terrain.terrainData;\n        Vector3 terrainPos = terrain.GetPosition();\n\n        // Convert world position to terrain coordinates\n        float xPercent = (worldPosition.x - terrainPos.x) / terrainData.size.x;\n        float zPercent = (worldPosition.z - terrainPos.z) / terrainData.size.z;\n\n        int centerX = (int)(xPercent * terrainData.heightmapResolution);\n        int centerZ = (int)(zPercent * terrainData.heightmapResolution);\n\n        int radiusInSamples = (int)(radius * terrainData.heightmapResolution / terrainData.size.x);\n\n        // Modify height within radius\n        for (int x = Mathf.Max(0, centerX - radiusInSamples); x < Mathf.Min(terrainData.heightmapResolution, centerX + radiusInSamples); x++)\n        {\n            for (int z = Mathf.Max(0, centerZ - radiusInSamples); z < Mathf.Min(terrainData.heightmapResolution, centerZ + radiusInSamples); z++)\n            {\n                float distance = Mathf.Sqrt(Mathf.Pow(x - centerX, 2) + Mathf.Pow(z - centerZ, 2));\n                if (distance <= radiusInSamples)\n                {\n                    float falloff = 1f - (distance / radiusInSamples);\n                    heightMap[x, z] += heightDelta * falloff;\n                    heightMap[x, z] = Mathf.Clamp01(heightMap[x, z]);\n                }\n            }\n        }\n\n        // Apply the modified heightmap\n        terrainData.SetHeights(0, 0, heightMap);\n    }\n}\n'})}),"\n",(0,a.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Create a Unity scene with realistic lighting and materials using PBR"}),"\n",(0,a.jsx)(n.li,{children:"Implement a camera sensor simulation that outputs RGB and depth images"}),"\n",(0,a.jsx)(n.li,{children:"Develop a LIDAR simulation system that outputs realistic point cloud data"}),"\n",(0,a.jsx)(n.li,{children:"Create an IMU simulation that provides accurate acceleration and rotation data"}),"\n",(0,a.jsx)(n.li,{children:"Build a procedural environment generator with physics-based objects"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Unity Rendering Documentation: ",(0,a.jsx)(n.a,{href:"https://docs.unity3d.com/Manual/rendering-index.html",children:"https://docs.unity3d.com/Manual/rendering-index.html"})]}),"\n",(0,a.jsxs)(n.li,{children:["Unity HDRP Documentation: ",(0,a.jsx)(n.a,{href:"https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@latest",children:"https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@latest"})]}),"\n",(0,a.jsxs)(n.li,{children:["Unity Robotics Package: ",(0,a.jsx)(n.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,a.jsxs)(n.li,{children:["Unity Perception Package: ",(0,a.jsx)(n.a,{href:"https://github.com/Unity-Technologies/Unity-Perception",children:"https://github.com/Unity-Technologies/Unity-Perception"})]}),"\n",(0,a.jsxs)(n.li,{children:["Physically-Based Rendering in Unity: ",(0,a.jsx)(n.a,{href:"https://docs.unity3d.com/Manual/MaterialsMenu.html",children:"https://docs.unity3d.com/Manual/MaterialsMenu.html"})]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var t=i(6540);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);