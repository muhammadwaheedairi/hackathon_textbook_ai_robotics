"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[5853],{2807:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>t,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-2-lidar-imu-sensors","title":"IMU Sensors and ROS 2 Integration","description":"Overview","source":"@site/docs/module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-2-lidar-imu-sensors.md","sourceDirName":"module-1-robotic-nervous-system/week-1-introduction-to-physical-ai","slug":"/module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-2-lidar-imu-sensors","permalink":"/hackathon_textbook_ai_robotics/docs/module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-2-lidar-imu-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/muhammadwaheedairi/hackathon_textbook_ai_robotics/edit/main/my-website/docs/module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-2-lidar-imu-sensors.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"IMU Sensors and ROS 2 Integration","sidebar_label":"Chapter 2: IMU Sensors","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: What is Physical AI?","permalink":"/hackathon_textbook_ai_robotics/docs/module-1-robotic-nervous-system/week-1-introduction-to-physical-ai/chapter-1-what-is-physical-ai"},"next":{"title":"Chapter 3: Nodes & Topics","permalink":"/hackathon_textbook_ai_robotics/docs/module-1-robotic-nervous-system/week-2-ros-2-fundamentals/chapter-3-nodes-topics"}}');var o=s(4848),r=s(8453);const a={title:"IMU Sensors and ROS 2 Integration",sidebar_label:"Chapter 2: IMU Sensors",sidebar_position:2},t="Chapter 2: IMU Sensors and ROS 2 Integration",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"IMU Sensors",id:"imu-sensors",level:2},{value:"IMU Components",id:"imu-components",level:3},{value:"IMU Applications in Robotics",id:"imu-applications-in-robotics",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Common Sensor Message Types",id:"common-sensor-message-types",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"IMU Data Processing",id:"imu-data-processing",level:3},{value:"Basic Sensor Fusion Example",id:"basic-sensor-fusion-example",level:3},{value:"Visualization of Sensor Data",id:"visualization-of-sensor-data",level:3},{value:"Summary",id:"summary",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function d(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-2-imu-sensors-and-ros-2-integration",children:"Chapter 2: IMU Sensors and ROS 2 Integration"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"This chapter explores Inertial Measurement Units (IMUs) and their integration with ROS 2 for robot perception. You'll learn how IMUs measure orientation and motion, and how to combine LIDAR and IMU data for comprehensive environmental awareness."}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(e.admonition,{title:"Learning Objectives",type:"info",children:[(0,o.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Understand IMU components and their functions"}),"\n",(0,o.jsx)(e.li,{children:"Process IMU data in ROS 2 applications"}),"\n",(0,o.jsx)(e.li,{children:"Integrate multiple sensor types for sensor fusion"}),"\n",(0,o.jsx)(e.li,{children:"Implement basic sensor fusion for obstacle detection"}),"\n"]})]}),"\n",(0,o.jsx)(e.h2,{id:"imu-sensors",children:"IMU Sensors"}),"\n",(0,o.jsx)(e.p,{children:"Inertial Measurement Units (IMUs) combine accelerometers, gyroscopes, and sometimes magnetometers to measure the robot's orientation, velocity, and gravitational forces."}),"\n",(0,o.jsx)(e.h3,{id:"imu-components",children:"IMU Components"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Accelerometer"}),": Measures linear acceleration"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Gyroscope"}),": Measures angular velocity"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Magnetometer"}),": Measures magnetic field orientation (compass)"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"imu-applications-in-robotics",children:"IMU Applications in Robotics"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Robot pose estimation"}),"\n",(0,o.jsx)(e.li,{children:"Motion tracking and control"}),"\n",(0,o.jsx)(e.li,{children:"Stabilization systems"}),"\n",(0,o.jsx)(e.li,{children:"Dead reckoning navigation"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,o.jsx)(e.p,{children:"The Robot Operating System 2 (ROS 2) provides standardized interfaces for sensor integration, making it easier to work with LIDAR and IMU sensors in robotics applications."}),"\n",(0,o.jsx)(e.h3,{id:"common-sensor-message-types",children:"Common Sensor Message Types"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"sensor_msgs/LaserScan"}),": For LIDAR data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"sensor_msgs/Imu"}),": For IMU data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"sensor_msgs/PointCloud2"}),": For 3D point cloud data"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,o.jsx)(e.h3,{id:"imu-data-processing",children:"IMU Data Processing"}),"\n",(0,o.jsx)(e.p,{children:"Here's a ROS 2 Python node for processing IMU data:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Imu\nfrom geometry_msgs.msg import Vector3\nimport math\n\nclass ImuSubscriber(Node):\n    def __init__(self):\n        super().__init__('imu_subscriber')\n        self.subscription = self.create_subscription(\n            Imu,\n            '/imu/data',\n            self.imu_callback,\n            10)\n        self.subscription\n        self.get_logger().info('IMU Subscriber node initialized')\n\n    def imu_callback(self, msg):\n        \"\"\"Process incoming IMU data\"\"\"\n        orientation = msg.orientation\n        roll, pitch, yaw = self.quaternion_to_euler(\n            orientation.x, orientation.y, orientation.z, orientation.w)\n\n        angular_velocity = msg.angular_velocity\n        linear_acceleration = msg.linear_acceleration\n\n        self.get_logger().info(\n            f'Orientation - Roll: {math.degrees(roll):.2f}\xb0, '\n            f'Pitch: {math.degrees(pitch):.2f}\xb0, '\n            f'Yaw: {math.degrees(yaw):.2f}\xb0'\n        )\n\n    def quaternion_to_euler(self, x, y, z, w):\n        \"\"\"Convert quaternion to Euler angles (roll, pitch, yaw)\"\"\"\n        sinr_cosp = 2 * (w * x + y * z)\n        cosr_cosp = 1 - 2 * (x * x + y * y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        sinp = 2 * (w * y - z * x)\n        if abs(sinp) >= 1:\n            pitch = math.copysign(math.pi / 2, sinp)\n        else:\n            pitch = math.asin(sinp)\n\n        siny_cosp = 2 * (w * z + x * y)\n        cosy_cosp = 1 - 2 * (y * y + z * z)\n        yaw = math.atan2(siny_cosp, cosy_cosp)\n\n        return roll, pitch, yaw\n\ndef main(args=None):\n    rclpy.init(args=args)\n    imu_subscriber = ImuSubscriber()\n\n    try:\n        rclpy.spin(imu_subscriber)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        imu_subscriber.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(e.h3,{id:"basic-sensor-fusion-example",children:"Basic Sensor Fusion Example"}),"\n",(0,o.jsx)(e.p,{children:"Here's a simple example of combining LIDAR and IMU data:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom geometry_msgs.msg import Twist\nimport numpy as np\nimport math\n\nclass SensorFusionNode(Node):\n    def __init__(self):\n        super().__init__(\'sensor_fusion_node\')\n\n        self.lidar_subscription = self.create_subscription(\n            LaserScan, \'/scan\', self.lidar_callback, 10)\n        self.imu_subscription = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10)\n\n        self.cmd_vel_publisher = self.create_publisher(Twist, \'/cmd_vel\', 10)\n\n        self.latest_lidar_data = None\n        self.latest_imu_data = None\n\n        self.get_logger().info(\'Sensor Fusion Node initialized\')\n\n    def lidar_callback(self, msg):\n        """Store latest LIDAR data"""\n        self.latest_lidar_data = msg\n\n        if self.process_lidar_for_obstacles():\n            self.get_logger().warn(\'Obstacle detected! Stopping robot.\')\n            self.stop_robot()\n\n    def imu_callback(self, msg):\n        """Store latest IMU data"""\n        self.latest_imu_data = msg\n\n        orientation = msg.orientation\n        roll, pitch, yaw = self.quaternion_to_euler(\n            orientation.x, orientation.y, orientation.z, orientation.w)\n\n        self.get_logger().info(f\'Robot orientation: Yaw={math.degrees(yaw):.2f}\xb0\')\n\n    def process_lidar_for_obstacles(self):\n        """Check if there are obstacles in front of the robot"""\n        if self.latest_lidar_data is None:\n            return False\n\n        ranges = np.array(self.latest_lidar_data.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) == 0:\n            return False\n\n        center_idx = len(ranges) // 2\n        front_range = ranges[center_idx - len(ranges)//10:center_idx + len(ranges)//10]\n        front_valid = front_range[np.isfinite(front_range)]\n\n        if len(front_valid) > 0:\n            min_front_distance = np.min(front_valid)\n            return min_front_distance < 1.0\n\n        return False\n\n    def stop_robot(self):\n        """Send stop command to robot"""\n        stop_cmd = Twist()\n        stop_cmd.linear.x = 0.0\n        stop_cmd.angular.z = 0.0\n        self.cmd_vel_publisher.publish(stop_cmd)\n\n    def quaternion_to_euler(self, x, y, z, w):\n        """Convert quaternion to Euler angles"""\n        sinr_cosp = 2 * (w * x + y * z)\n        cosr_cosp = 1 - 2 * (x * x + y * y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        sinp = 2 * (w * y - z * x)\n        if abs(sinp) >= 1:\n            pitch = math.copysign(math.pi / 2, sinp)\n        else:\n            pitch = math.asin(sinp)\n\n        siny_cosp = 2 * (w * z + x * y)\n        cosy_cosp = 1 - 2 * (y * y + z * z)\n        yaw = math.atan2(siny_cosp, cosy_cosp)\n\n        return roll, pitch, yaw\n\ndef main(args=None):\n    rclpy.init(args=args)\n    sensor_fusion_node = SensorFusionNode()\n\n    try:\n        rclpy.spin(sensor_fusion_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sensor_fusion_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"visualization-of-sensor-data",children:"Visualization of Sensor Data"}),"\n",(0,o.jsx)(e.p,{children:"For visualizing sensor data, you can use RViz2 which comes with ROS 2. Here's a simple example of publishing data for visualization:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom visualization_msgs.msg import Marker\nfrom geometry_msgs.msg import Point\nimport math\n\nclass SensorVisualizationNode(Node):\n    def __init__(self):\n        super().__init__('sensor_visualization_node')\n\n        self.lidar_subscription = self.create_subscription(\n            LaserScan, '/scan', self.lidar_callback, 10)\n\n        self.marker_publisher = self.create_publisher(Marker, '/lidar_points', 10)\n\n        self.get_logger().info('Sensor Visualization Node initialized')\n\n    def lidar_callback(self, msg):\n        \"\"\"Convert LIDAR scan to visualization markers\"\"\"\n        marker = Marker()\n        marker.header = msg.header\n        marker.ns = \"lidar_points\"\n        marker.id = 0\n        marker.type = Marker.POINTS\n        marker.action = Marker.ADD\n\n        marker.scale.x = 0.05\n        marker.scale.y = 0.05\n        marker.scale.z = 0.05\n\n        marker.color.r = 1.0\n        marker.color.g = 0.0\n        marker.color.b = 0.0\n        marker.color.a = 1.0\n\n        angle = msg.angle_min\n        for i, range_val in enumerate(msg.ranges):\n            if not math.isinf(range_val) and not math.isnan(range_val):\n                x = range_val * math.cos(angle)\n                y = range_val * math.sin(angle)\n\n                point = Point()\n                point.x = x\n                point.y = y\n                point.z = 0.0\n\n                marker.points.append(point)\n\n            angle += msg.angle_increment\n\n        self.marker_publisher.publish(marker)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    vis_node = SensorVisualizationNode()\n\n    try:\n        rclpy.spin(vis_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        vis_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"IMU sensors provide essential orientation and motion data for robots, complementing LIDAR's distance measurements. By integrating multiple sensor types through ROS 2, robots can achieve comprehensive environmental awareness and make informed decisions about navigation and interaction."}),"\n",(0,o.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsx)(e.admonition,{title:"Key Takeaways",type:"tip",children:(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"IMUs combine accelerometers, gyroscopes, and magnetometers for motion sensing"}),"\n",(0,o.jsx)(e.li,{children:"ROS 2 provides standardized message types for sensor data integration"}),"\n",(0,o.jsx)(e.li,{children:"Sensor fusion combines data from multiple sensors for robust perception"}),"\n",(0,o.jsx)(e.li,{children:"Proper quaternion-to-Euler conversion is essential for orientation processing"}),"\n"]})}),"\n",(0,o.jsx)(e.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,o.jsx)(e.p,{children:"In the next chapter, we'll dive into ROS 2 fundamentals, exploring nodes, topics, and the publish-subscribe communication pattern that enables distributed robotics systems."})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,s)=>{s.d(e,{R:()=>a,x:()=>t});var i=s(6540);const o={},r=i.createContext(o);function a(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);